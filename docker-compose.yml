services:
  ollama:
    image: ollama/ollama
    container_name: ollama
    ports:
      - '11434:11434'
    volumes:
      - ollama_models:/root/.ollama
    restart: unless-stopped
    entrypoint:
      [
        '/bin/sh',
        '-c',
        'ollama serve & sleep 3 && ollama pull openchat && tail -f /dev/null',
      ]
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]

  # tts:
  #   build:
  #     dockerfile: images/tts-server/Dockerfile
  #     context: .
  #   ports:
  #     - '5002:5002'

  oraculo:
    build:
      context: .
      dockerfile: images/node/Dockerfile
    container_name: oraculo
    ports:
      - '8080:8080'
    environment:
      - OLLAMA_URL=http://ollama:11434
    volumes:
      - ./public:/app/public
      - ./.env:/app/.env
    depends_on:
      - ollama
    restart: unless-stopped

volumes:
  ollama_models:
